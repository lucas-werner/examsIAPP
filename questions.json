[
  {
    "question": "Which of the following is a method that helps to ensure AI integrity and that data is representative, accurate and unbiased? (rev)",
    "options": [
      "A. Tracking data lineage.",
      "B. Assuming the data is accurate.",
      "C. Purchasing data from a vendor.",
      "D. Reversioning the data internally."
    ],
    "answer": "A",
    "rationale": "Data lineage tracks data over time from the source to any other intervening programs or uses, and ultimately to the AI program or process utilizing it. Knowing where and how data has been used and manipulated before it is incorporated into an AI program or process helps ensure the data being used is accurate and appropriate."
  },
  {
    "question": "You are tasked with designing an AI system to predict customer attrition for a telecommunications company. During the design phase, you are focusing on developing the data strategy. Which of the following statements best describes the critical importance of data gathering in this phase? (rev)",
    "options": [
      "A. It primarily aims to reduce data storage costs, prioritizing low-cost repositories over data quality or relevance.",
      "B. It ensures the AI system has access to high-quality and relevant data, which is the fuel for training effective models.",
      "C. It focuses on designing attractive user interfaces for data input, catering to user experience over data completeness or accuracy.",
      "D. It is only important for regulatory compliance, ensuring data practices adhere to regulations but not impacting the AI system's performance."
    ],
    "answer": "B",
    "rationale": "Implementing a data strategy during the AI system design phase is crucial because it ensures access to high-quality and relevant data, which is fundamental for training effective AI models. The quality and relevance of data directly impacts the performance and accuracy of AI systems. The other options are irrelevant aspects of an AI system's design phase."
  },
  {
    "question": "A US manufacturing company is implementing an algorithm-based system to assist with screening job applicants and making hiring decisions. Which of the following is least likely to provide guidance on minimizing potential discrimination and bias with this system? (rev)",
    "options": [
      "A. Fair Credit Reporting Act (FCRA).",
      "B. American with Disabilities Act (ADA).",
      "C. National Artificial Intelligence Initiative Act (NAIIA).",
      "D. Equal Employment Opportunity Commission (EEOC) enforcement actions."
    ],
    "answer": "C",
    "rationale": "The National Artificial Intelligence Initiative Act of 2020 establishes a national initiative to advance AI research and development. It does not provide guidance on minimizing potential discrimination and bias, although these are considerations for the various committees formed thereunder to address. The ADA has direct application to the use of software algorithms to make employment decisions. The FCRA imposes certain obligations on an organization using credit reporting information for employment purposes and adverse employment actions based on credit reporting information. While EEOC enforcement actions are not binding legal standards beyond the target company, enforcement actions for alleged discrimination and bias related to AI and automated decision-making systems provides direct evidence of the EEOC's view on how such systems may result in discrimination and bias."
  },
  {
    "question": "In the context of workforce readiness for AI, what is an essential consideration for businesses to fully leverage AI benefits responsibly? (rev)",
    "options": [
      "A. Focusing on training a select IT task force in advanced AI techniques.",
      "B. Avoiding employee training on AI to prevent over-reliance on technology.",
      "C. Implementing comprehensive training programs across various departments.",
      "D. Outsourcing AI-related tasks to third-party specialists to reduce training needs."
    ],
    "answer": "C",
    "rationale": "To maximize the benefits of AI, businesses should implement comprehensive training programs that encompass not just technical AI skills but also ethical considerations of AI usage. This approach ensures a broad-based understanding of AI across the organization, enabling more effective and responsible use of AI technologies."
  },
  {
    "question": "What is the purpose of the model card in assessing the readiness of an AI model for production? (rev)",
    "options": [
      "A. It stores the model's input data that is used to generate outputs.",
      "B. It provides the correct outputs against which the AI model is tested.",
      "C. It holds the model's final 'Dev' code to provide a performance baseline.",
      "D. It documents the model's performance, limitations and intended use cases."
    ],
    "answer": "D",
    "rationale": "Model cards are short documents provided with machine learning models that explain the context in which the models are intended to be used, details of the performance evaluation procedures and any other relevant information."
  },
  {
    "question": "The manager of a call center decides to use an AI system to record and conduct sentiment analysis on interactions between customers and call center agents. Prior to using this data to evaluate the performance of the agents, what step should be implemented to minimize error in the evaluations? (rev)",
    "options": [
      "A. A security review of the AI system.",
      "B. A manual review of the recordings.",
      "C. An estimate of call rates to the center.",
      "D. A retention policy for aggregate reports."
    ],
    "answer": "B",
    "rationale": "Human review or supervision of the recorded call should be done to ensure the sentiment analysis of the AI system is accurate prior to using the data to evaluate the agent's performance. Retention of data is important, but aggregate report data will not create risk for an individual. An estimate of call rates may help in staffing or workforce planning but won't directly affect an individual's performance rating. A security review of the AI will ensure security of the system, but also does not directly affect the individual or how their performance is evaluated."
  },
  {
    "question": "SCENARIO I: AlphaTech, a renowned technology company in S達o Paulo, Brazil... \n 7. With this solution in sight, what initial step should AlphaTech take to ensure the interoperability of AI risk management with privacy risk management in its operations? (rev)",
    "options": [
      "A. Conduct regular simulations and tests.",
      "B. Implement continuous audit protocols.",
      "C. Create a specialized multidisciplinary team.",
      "D. Develop ethical and transparent AI algorithms."
    ],
    "answer": "C",
    "rationale": "While each of the steps listed is important at various stages of development and implementation, the first step should be to create a team that understands the complexities and needs of both privacy risk management and AI risk management. The reason for prioritizing the creation of a specialized multidisciplinary team is twofold: a. Integration of diversified knowledge: A multidisciplinary team brings together specialists in different areas, such as AI, data protection and digital law. This diversity of knowledge is essential to fully understand both the technical aspects of AI and the legal and ethical implications related to data privacy; and b. Foundation for implementing: With a specialized team in place, the company will have the necessary resources to plan and execute other strategies more effectively. For example, the team can oversee the implementation of continuous audit protocols, guide the development of ethical and transparent AI algorithms, and plan regular simulations and tests."
  },
  {
    "question": "SCENARIO I: AlphaTech, a renowned technology company in S達o Paulo, Brazil... \n 8. Which of the following strategies would be most effective for AlphaTech to ensure privacy compliance when integrating AI into its operations? (rev)",
    "options": [
      "A. Delegate all the AI decisions to an automated algorithm.",
      "B. Implement a privacy training program for all employees.",
      "C. Focus on the technological development of AI without considering legal aspects.",
      "D. Reduce data collection to a minimum, regardless of the impact on AI effectiveness."
    ],
    "answer": "B",
    "rationale": "Implementing a privacy training program for all employees will help ensure everyone in the company is aware of the responsibilities and practices necessary to maintain compliance with the data protection law."
  },
  {
    "question": "SCENARIO I: AlphaTech, a renowned technology company in S達o Paulo, Brazil... \n 9. What is the best practice for AlphaTech to effectively integrate AI into operational risk monitoring without compromising data privacy? (rev)",
    "options": [
      "A. Allow full access to the AI system for all employees.",
      "B. Focus only on operational risks, ignoring privacy risks.",
      "C. Apply data minimization and transparency principles in AI.",
      "D. Delete all personal data from the system to avoid privacy risks."
    ],
    "answer": "C",
    "rationale": "Applying data minimization and transparency principles in AI implementation ensures that only necessary data is used and processes are transparent, balancing operational efficiency with privacy protection."
  },
  {
    "question": "SCENARIO I: AlphaTech, a renowned technology company in S達o Paulo, Brazil... \n 10. What approach should AlphaTech adopt to ensure the integration of AI into its operations aligns with best cybersecurity practices? (rev)",
    "options": [
      "A. Delegate cybersecurity exclusively to the IT team.",
      "B. Reduce focus on cybersecurity to increase AI efficiency.",
      "C. Rely entirely on traditional firewalls and antivirus software.",
      "D. Integrate cybersecurity into the design and development of AI."
    ],
    "answer": "D",
    "rationale": "Integrating cybersecurity into the design and development of AI from the beginning ensures security concerns are proactively addressed rather than being an afterthought. This is essential to protect both the company's infrastructure and the data it processes."
  },
  {
    "question": "Consider you are a privacy consultant with a tech company developing an AI-driven health-monitoring application. The application collects user data to provide personalized health insights. The company is dedicated to ensuring user privacy and seeks your advice. In the context of developing a privacy-enhanced AI health-monitoring application, which of the following measures would be most effective in aligning with privacy standards? (rev)",
    "options": [
      "A. Implementing user consent mechanisms and anonymizing collected data to protect user identities.",
      "B. Utilizing social media integration to enrich user profiles with additional lifestyle information and offers.",
      "C. Sharing raw user data with various pharmaceutical companies to facilitate targeted drug development.",
      "D. Storing user health data on a publicly accessible server for easy collaboration with health care researchers."
    ],
    "answer": "A",
    "rationale": "Obtaining consent from users empowers individuals to make informed decisions about the use of their health data. Furthermore, anonymizing involves removing personally identifiable information from the collected data, such as names, addresses and contact details."
  },
  {
    "question": "Which of the following is an important consideration for mitigating AI system errors? (rev)",
    "options": [
      "A. Excluding a review of previous incidents.",
      "B. Focusing exclusively on legal compliance.",
      "C. Adopting a uniform approach for all errors.",
      "D. Understanding the AI use case and the data type."
    ],
    "answer": "D",
    "rationale": "The AI use case and the data type involved in system errors will guide the method of mitigation needed. This allows for an appropriate response and helps to guide any updates or changes needed to avoid similar issues in the future."
  },
  {
    "question": "Which of the following should be included in the documentation of an AI model's impact assessment? (rev)",
    "options": [
      "A. Marketing and sales budgets.",
      "B. Stakeholder input and concerns.",
      "C. User demographics and feedback.",
      "D. Training algorithm and audit details."
    ],
    "answer": "B",
    "rationale": "Stakeholder inputs and concerns are important to be part of impact assessment, as it will provide key details on the output and how AI is performing, which will help in addressing issues. Training algorithm details and user demographics are required, but at the planning stage, which will help in access and eliminating any biased data. Marketing Budget is not a relevant option."
  },
  {
    "question": "In the design phase of AI development, privacy-enhancing technologies play a critical role in addressing data privacy concerns. Among these technologies, differential privacy and federated learning are significant. Given this context, which of the following best illustrates the application of differential privacy in the AI design phase? (rev)",
    "options": [
      "A. An AI model is trained in a centralized dataset in which individual data points are anonymized before being added to the dataset.",
      "B. An AI system enables multiple models to learn from separate datasets, then combines them to improve the overall model without sharing individual data points.",
      "C. An AI application uses encryption to secure data in transit between the client and server, ensuring that intercepted data cannot be read by unauthorized parties.",
      "D. An AI system adds random noise to the raw data it collects, ensuring that any output reflects general trends in the dataset but does not compromise individual data privacy."
    ],
    "answer": "D",
    "rationale": "This option directly aligns with the principles of differential privacy. Differential privacy is a technique used to ensure the privacy of individual data points in a dataset by adding statistical noise. This method allows the dataset to be used for analysis or AI model training while maintaining the confidentiality of individual data entries. The key aspect of differential privacy is that it provides insights into the general patterns or trends of the data without revealing sensitive information about any specific individual."
  },
  {
    "question": "When implementing responsible AI governance and risk management, what is a critical consideration for testing and evaluation in alignment with a specific use case? (rev)",
    "options": [
      "A. Include potentially malicious data in the test.",
      "B. There is no need for repeatability assessments for novel cases.",
      "C. Use the same testing and evaluation approach for all algorithms.",
      "D. Exclude cases that the AI has not encountered during its training."
    ],
    "answer": "A",
    "rationale": "Incorporating potentially malicious data into the testing process would enable the assessment of the AI's robustness and resilience against adversarial inputs and ensure that it behaves safely in real-world scenarios. The other options are not aligned with the best practices for responsible AI testing."
  },
  {
    "question": "The Voter Registration Department of a state agency has implemented an AI tool to scan and cross-reference driver's license information and voter registration application information to detect fraud and identity theft. In assessing the effectiveness of the AI tool, which of the following is NOT a key assessment activity? (rev)",
    "options": [
      "A. Auditing for bias and discrimination across multiple demographic groups.",
      "B. Confirming that all counties have analyzed the same number of voter registration applications.",
      "C. Testing for the frequency of false positives that inaccurately identify fraud where it does not exist.",
      "D. Collecting feedback from users to identify errors or aspects of the AI tool that need to be improved."
    ],
    "answer": "B",
    "rationale": "In assessing an AI tool after deployment, it is important to determine error rates by testing and by collecting feedback from users and stakeholders. With an AI tool that could potentially discriminate and exclude persons from voting, bias testing is also important. Answer C is not a key assessment task because different counties may have different populations. Also, the number of applications analyzed by each county does not directly relate to the tool's performance or effectiveness."
  },
  {
    "question": "SCENARIO II: Easy to Hire is a U.S.-based company that develops products and services to support its client companies in hiring top talents... \n 17. What will be the classification of the AI system Hire in One Second be under the EU's Artificial Intelligence Act? (rev)",
    "options": [
      "A. High risk.",
      "B. Limited risk.",
      "C. Minimal risk.",
      "D. Unacceptable risk."
    ],
    "answer": "A",
    "rationale": "AI systems intended to be used for recruitment or selection of natural persons, notably to place targeted job advertisements, and to analyze and filter job applications and evaluate candidates are classified as high risk under the EU AI Act. The high-risk classification is due to the effect these actions have on an individual's employment opportunities and the bias AI could introduce if not regulated properly."
  },
  {
    "question": "SCENARIO II: Easy to Hire is a U.S.-based company that develops products and services to support its client companies in hiring top talents... \n 18. Easy to Hire planned to sell its product directly within the European market and commercialize it through a distribution network. In that context, who will be the provider of the AI system under the EU AI Act? (rev)",
    "options": [
      "A. Healthcare.Gmb.",
      "B. Emma, as the ethics officer.",
      "C. The operations director of Hirenow.Inc.",
      "D. Easy to Hire and its distribution network."
    ],
    "answer": "D",
    "rationale": "The EU AI Act defines providers and users of AI systems. The provider is the entity which develops the AI system and makes it available through the market (supplying of an AI system for distribution or use in the EU). The deployer is the organization or individual that utilizes the AI system for specific purposes. Among other names, deployers may be referred to as importers, distributors and operators."
  },
  {
    "question": "SCENARIO II: Easy to Hire is a U.S.-based company that develops products and services to support its client companies in hiring top talents... \n 19. Among this list of regulations, which is legally binding and requires compliance from both AI users and providers? (rev)",
    "options": [
      "A. The European AI Act.",
      "B. The OECD Guidelines on AI.",
      "C. The Blueprint for an AI Bill of Rights.",
      "D. The Singapore AI Governance Framework."
    ],
    "answer": "A",
    "rationale": "The only binding instrument within the choices listed is the European AI Act. The OECD Guidelines on AI from 2019, the Blueprint for an AI Bill of Rights adopted by the White House in 2021 and the Singapore AI Governance Framework of 2019 are guidelines and part of the plethora of frameworks published in the last few years to aid organizations in building AI ethically."
  },
  {
    "question": "When assessing the success of an AI system meeting its objectives, which of the following approaches best aligns with the requirement to ensure a comprehensive evaluation while avoiding automation bias? (rev)",
    "options": [
      "A. Evaluate and align predefined benchmarks that will provide evidence of having achieved your system goals.",
      "B. Rely on the AI system's output to determine if the goals were achieved, as this will provide a reliable and objective measure.",
      "C. Conduct a review that includes the AI system's output, human interpretation, and potential secondary or unintended outputs.",
      "D. Focus on user feedback about the AI system's performance to directly measure the system's effectiveness in meeting the objectives."
    ],
    "answer": "C",
    "rationale": "This is a comprehensive approach as it includes different testing initiatives. By integrating the AI system's output, human interpretation and potential secondary or unintended outputs, you will avoid automation bias (when only relying on the output), as well as the limitation of having only human feedback that might not fully capture AI specificities. Additionally, this process avoids a narrow focus, which would be the result of using only a benchmark as a comparison item."
  },
  {
    "question": "Which of the following pairs provides examples of potential group harms associated with AI technologies? (rev)",
    "options": [
      "A. Safety and deep fakes.",
      "B. Acceleration and reputational.",
      "C. Mass surveillance and facial recognition.",
      "D. Carbon dioxide emission and agricultural."
    ],
    "answer": "C",
    "rationale": "Mass surveillance and facial recognition can lead to group harm given the potential use of AI technology to target and/or discriminate against specific groups/demographics. Safety and deep fakes are examples of societal harm, which is different than group harms in that they are not targeted against a specific group or demographic. Acceleration refers to the potential harm caused by AI advancing beyond the ability to safeguard it properly. Reputational harm refers to the potential risk to organizations or individuals from poorly managed AI or competitors creating deep fakes. Carbon dioxide emissions and agricultural harm refer to the possibility of increased computer reliance affecting the environment."
  },
  {
    "question": "Put the following AI system planning phase steps in the right order by letter.\n A. Identify laws that apply\n B. Determine the business problem to be solved by the AI system\n C. Identify necessary data for the AI system\n D. Determine the specific use cases\n E. Identify gaps and risks to the use cases (rev)",
    "options": [
      "A. B, D, A, E, C",
      "B. A, B, C, D, E",
      "C. E, D, C, B, A",
      "D. B, C, D, A, E"
    ],
    "answer": "A",
    "rationale": "While there are other steps involved in planning to introduce an AI system to an organization, and some steps may occur more than once, the general order of those listed is: Determine the business problem, Determine specific use case(s), Identify laws that apply, Identify use case gaps and risks, Identify the data that will be needed. By having a defined process, beginning with whether the AI tool solves a specific business issue, you help to guide responsible and appropriate AI use within your organization."
  },
  {
    "question": "What is the main purpose of conducting regular audits of an AI model? (rev)",
    "options": [
      "A. To verify the cost of the AI system is offset by profits.",
      "B. To ensure that the model has enough data for viable processing.",
      "C. To increase the speed and effectiveness of the model's operations.",
      "D. To evaluate performance, fairness and compliance with regulations."
    ],
    "answer": "D",
    "rationale": "Regular audits are conducted to ensure that the AI model operates fairly, reliably, and complies with applicable laws and ethical standards. This helps identify and address issues such as bias, performance deterioration or legal non-compliance."
  },
  {
    "question": "Which of the following is NOT true about the relationship of explainability and transparency as they relate to AI? (rev)",
    "options": [
      "A. They are synonymous.",
      "B. They support trustworthy AI.",
      "C. They are distinct characteristics that support each other.",
      "D. They enable users of the system to understand the outcomes."
    ],
    "answer": "A",
    "rationale": "Both are types of documentation that help users understand how the system produces its outputs. Both support trustworthy AI as defined by NIST, OECD and others. 'Explainability and transparency are distinct characteristics that support each other. Transparency can answer the question of 'what happened' in the system. Explainability can answer the question of 'how' a decision was made in the system' (NIST AI RMF, 3.5 Explainable and Interpretable). They are not synonymous. The words do not have nearly the same meaning but can be presented in ways that may make this appear to be the case."
  },
  {
    "question": "A regulator has ruled that the AI model used by some features of your product should not be used in its jurisdiction. What is the most robust way of reacting to this situation? (rev)",
    "options": [
      "A. Shut down the service in the jurisdiction to pressure the regulator to change its position.",
      "B. Create a second, separate version of the application and deploy it to users in the jurisdiction.",
      "C. Implement a feature flag to enable or disable the features based on a user's country of origin.",
      "D. Retrain and deploy your AI model immediately to prove you can react quickly to regulatory demands."
    ],
    "answer": "C",
    "rationale": "Feature flags can be toggled without major engineering efforts, and keeping the model offline during regulatory negotiations avoids unnecessary confrontations, such as requiring a redeploy."
  },
  {
    "question": "What is a key recommendation for assessing the reliability of general-purpose AI models after deployment? (rev)",
    "options": [
      "A. Limit assessments to specific use cases.",
      "B. Use only quantitative metrics for evaluation.",
      "C. Focus solely on pre-deployment testing results.",
      "D. Monitor and evaluate models in real-world conditions."
    ],
    "answer": "D",
    "rationale": "Continuously monitoring and evaluating AI models in real-world conditions ensures they remain reliable and effective as they face varied and dynamic environments. This approach helps identify any issues or degradation in performance, allowing for timely adjustments and improvements to maintain the integrity of AI systems."
  },
  {
    "question": "SCENARIO III: Z Corporation has launched a mobile finance application... \n 27. Which of the following should Z Corporation do as it grows to reduce the risk of bias during the app's ongoing design and development process? (rev)",
    "options": [
      "A. Retrain the app using as many fields of data as possible from users in South America and Asia.",
      "B. Remind users about the list of partner banks and their interest rates before finalizing a payment.",
      "C. Ensure that its AI governance framework is designed to include a more diverse set of stakeholders.",
      "D. Include requirements of privacy laws in its privacy policy, including for automated decision-making."
    ],
    "answer": "C",
    "rationale": "Diversity of thought, including through a demographically diverse team, can reduce the chance of bias during the design process (i.e., equitable design). Although a more globally applicable privacy notice and list of partner banks or interest rates would be helpful to improve transparency, they are unlikely to reduce bias. Retraining the app with more data fields can reduce bias, but, as the app's users are global, two continents are unlikely to be sufficient and the use of as many data fields as possible may breach the data protection principle of data minimization."
  },
  {
    "question": "SCENARIO III: Z Corporation has launched a mobile finance application... \n 28. Which of the following Asilomar AI principles are most relevant to Z Corporation when it's considering whether to remove users' ability to obtain a loan or use funds from their account? (rev)",
    "options": [
      "A. Importance, risks, research goal.",
      "B. Safety, judicial transparency, shared benefit.",
      "C. Research culture, race avoidance, human values.",
      "D. Failure transparency, human control, personal privacy."
    ],
    "answer": "D",
    "rationale": "If the feature determines to offer a loan when it is not beneficial to the user, this is likely to subvert the principle that the human user should decide whether to delegate a decision to an AI algorithm (human control). The user must have the right to access and control the personal data used in that decision (personal privacy). If the user wanted to challenge the automated decision, the user would not be able to ascertain why (failure transparency) the decision was made. The other answers are less suitable because the principles are less relevant. For example, the question does not ask about research (research goal or research culture) or use of AI by judges (judicial transparency)."
  },
  {
    "question": "SCENARIO III: Z Corporation has launched a mobile finance application... \n 29. When Z Corporation applies the OECD AI principles to its decision of whether to purchase the ready-made app, which of the following is NOT an important argument against the use of O Ltd.? (rev)",
    "options": [
      "A. Robustness, security and safety.",
      "B. Transparency and explainability.",
      "C. Human-centered values and fairness.",
      "D. Sustainable development and well-being."
    ],
    "answer": "D",
    "rationale": "While all the principles should be considered, there is little in the question which focuses on growth, prosperity and global development objectives (sustainable development and well-being). The use of O Ltd. could present concerns about the rule of law, human rights, democratic values (human-centered value and fairness), and privacy and digital security (robustness, security and safety). Using a pretrained algorithm would present concerns around the factors and logic used to make the decisions (transparency and explainability)."
  },
  {
    "question": "Which of the following is the most effective way for an AI developer to mitigate the risk of copyright infringement in developing and training an AI system? (rev)",
    "options": [
      "A. Confirm that any picture of a person the system generates does not resemble a living person.",
      "B. Confirm that the output is factually accurate and fully responds to each of the training prompts.",
      "C. Confirm that all the data in the foundational model and used for training constitutes a fair use of any existing work.",
      "D. Confirm that consent to use personal information to train the model has been obtained from the relevant individuals."
    ],
    "answer": "C",
    "rationale": "Copyright law recognizes that a 'fair use' of existing copyright material is permissible and does not constitute copyright infringement. By ensuring that all material used for training constitutes a 'fair use' of existing work, the developer can most effectively mitigate its potential for copyright infringement. While the other options may be relevant considerations in developing and training an AI model, they do not implicate or bear upon whether the developer may be liable for copyright infringement."
  },
  {
    "question": "Which of the following is NOT a key feature in determining what laws apply to the deployment of an AI model? (rev)",
    "options": [
      "A. The sector in which the model is being used.",
      "B. The technology stack used to develop the model.",
      "C. The jurisdiction where the model will be deployed.",
      "D. The type of information used by the model as its training set."
    ],
    "answer": "B",
    "rationale": "A technology stack is the collection of frameworks, tools, platforms and libraries used to build and deploy AI. While including the laws that apply to the jurisdiction(s) in which the AI tool will be deployed is important when building the technology stack, the stack itself is not specifically subject to those laws. There may be laws based on the model's training on personal information or copyrighted material, jurisdiction-specific laws, and sector-specific laws (e.g., for the healthcare sector)."
  },
  {
    "question": "Why should an AI developer separate data into training and test sets? (rev)",
    "options": [
      "A. To create models that can be trained quickly.",
      "B. To reduce the inherent biases in stochastic gradient descent.",
      "C. To avoid overfitting to the specific characteristics of the training data.",
      "D. To improve the test validation scores by presenting multiple datasets."
    ],
    "answer": "C",
    "rationale": "It is best practice to separate training and test sets to ensure any random biases in the training set do not carry over into the final model. In machine learning, overfitting occurs when an algorithm fits too closely or even exactly to its training data, resulting in a model that can't make accurate predictions or conclusions from any data other than the training data."
  },
  {
    "question": "When considering the implementation of AI systems, how should companies educate users to best address their concerns? (rev)",
    "options": [
      "A. Abort the AI system to avoid addressing user concerns.",
      "B. Assume that users will self-educate through online resources.",
      "C. Provide highly technical details relevant only to AI professionals.",
      "D. Offer comprehensive information on AI functionalities and limitations."
    ],
    "answer": "D",
    "rationale": "To effectively address user concerns, companies should provide comprehensive and accessible information regarding the AI system. This includes educating users on the capabilities and limitations of AI to ensure that they have a balanced and realistic understanding of the AI technology in place."
  },
  {
    "question": "Which of the following is a key element in ensuring responsible data governance when deploying an AI model? (rev)",
    "options": [
      "A. Storing all data indefinitely to allow future analysis.",
      "B. Implementing data minimization and retention limits.",
      "C. Only focusing on data quality without considering privacy.",
      "D. Collecting as much data as possible, regardless of its relevance."
    ],
    "answer": "B",
    "rationale": "Responsible data governance requires collecting only the necessary data and enforcing retention limits to comply with privacy regulations like GDPR. It ensures that data usage is both relevant and legally compliant."
  },
  {
    "question": "Alex is working for a public transit agency that is building out its AI program. He is collaborating with a local university to work on an AI project that involves what the NIST AI Risk Management Framework defines as social responsibility. Which proposal below best aligns with the concepts of social responsibility? (rev)",
    "options": [
      "A. Using AI-assisted software to analyze anonymized ridership data to fulfill government reporting requirements.",
      "B. Attaching sensors on buses to determine and assess heavy traffic periods on specific routes to provide accurate travel time to passengers.",
      "C. Analyzing video from station surveillance cameras to determine when office trash cans need to be emptied to save staff from unnecessary trips.",
      "D. Developing an AI-based mobile application that provides pseudonymized assistance to disabled customers booking point-to-point ride services."
    ],
    "answer": "D",
    "rationale": "NIST refers to the organization's social responsibility as considering the 'impacts of its decisions and activities on society and the environment through transparent and ethical behavior.' While each of these are important or useful in one way or another, providing ride assistance to disabled customers meets the goal of ethical social behavior. By pseudonymizing the information and the service itself, the company is providing a socially responsible service that protects the individual."
  },
  {
    "question": "The engineering team is working on training an AI model with a large, new dataset culled from social media. The team has built out the model to predict trends in car buying for the coming year based on social media posts. The AI model has a clear bias toward one particular automotive model. It turns out the recent data input was pulled when the car was featured in a blockbuster Hollywood movie. This is an example of which type of AI bias? (rev)",
    "options": [
      "A. Human-cognitive.",
      "B. Systemic and directed.",
      "C. Computational and statistical.",
      "D. Psychological and sociological."
    ],
    "answer": "C",
    "rationale": "Computational and statistical biases may stem from errors due to non-representative samples. In this example, the data is skewed based on the movie release."
  },
  {
    "question": "SCENARIO IV: NMATO, a multinational health care company... \n 37. What is a primary consideration for Tochi when tailoring AI governance to the organization? (rev)",
    "options": [
      "A. The availability and expertise of the organization's IT team.",
      "B. The organization's budget constraints and financial resources.",
      "C. The unique context, culture and objectives of the organization.",
      "D. Emerging trends and innovations in the broader industry landscape."
    ],
    "answer": "C",
    "rationale": "While Tochi has worked for five years at NMATO, his focus was on privacy risk management. At this time, his focus needs to be on how AI will be used by examining the context, culture and objectives of the organization. He must evaluate the context and how best practices for AI use will fit within the organization."
  },
  {
    "question": "SCENARIO IV: NMATO, a multinational health care company... \n 38. To strengthen the AI governance program early in its build-out, Tochi must do which of the following? (rev)",
    "options": [
      "A. Block third-party AI solutions from being deployed in the organization.",
      "B. Evaluate technology solutions different stakeholders can leverage in assessing AI solutions.",
      "C. Create a new organization charter and hire AI experts to build new AI governance processes.",
      "D. Understand the stakeholders involved and engage them early to identify areas of partnership."
    ],
    "answer": "D",
    "rationale": "AI governance requires a diverse set of stakeholders due to the multifaceted nature of AI harms and diverse perspectives that can be leveraged to enrich the program. Tochi must demonstrate inclusiveness internally and potentially do an assessment to identify if there are gaps that may be fulfilled by an additional hire."
  },
  {
    "question": "SCENARIO IV: NMATO, a multinational health care company... \n 39. Which of the following describes NMATO's governance model? (rev)",
    "options": [
      "A. Hybrid.",
      "B. Centralized.",
      "C. Cooperative.",
      "D. Decentralized."
    ],
    "answer": "A",
    "rationale": "Best practice is to leverage existing governance models. NMATO currently has a hybrid model, given that risk evaluations happen locally with a coordination mechanism at the head office. Operating a hybrid model also allows for the combination of centralized and local governance. This is typically seen when a large organization assigns a main individual responsibility for AI-related affairs, and the local entities then fulfill and support the policies and directives from the central governing body."
  },
  {
    "question": "ABC Corp is negotiating a contract with a vendor for a generative AI system to be used by ABC Corp's marketing team. Which of the following would be of least concern to ABC Corp when negotiating the agreement? (rev)",
    "options": [
      "A. ABC Corp not having copyright in the output generated by the vendor's AI system.",
      "B. ABC Corp not having a patent in order to use the algorithms of the vendor's AI system.",
      "C. ABC Corp losing its own trade secrets when providing inputs to align the algorithms of the vendor's AI system.",
      "D. ABC Corp infringing the intellectual property rights of others when using the output generated by the vendor's AI system."
    ],
    "answer": "B",
    "rationale": "ABC Corp does not need its own patent to use the vendor's AI system since the vendor would permit ABC Corp to use any patent the vendor had (if any). The other options relate to ensuring that ABC Corp can use the vendor's AI system while maintaining its own IP rights or not infringing the IP rights of others, which are issues particularly pertinent to generative AI."
  },
  {
    "question": "Brad is the Chief Technology Officer for Chip Zone, a chip manufacturer for the video game industry. The business has grown dramatically over the past two years and Brad needs an additional engineer to keep up with demand for new gaming chips. Brad prompts ChatGPT to draft a job description for his talent recruiters to use in advertising the engineering position. Which of the following results should Brad NOT include in the job description? (rev)",
    "options": [
      "A. The successful applicant will be a collaborative team player, detail-oriented, with creative problem-solving skills. They must provide two verifiable references from an employer or a recognized educator in the field.",
      "B. The successful applicant must demonstrate appropriate skills in chip design and engineering with a minimum of two years' experience and must be able to work 40 hours per week onsite at the ChipZone headquarters.",
      "C. The successful applicant will demonstrate skills in chip design and engineering, including at least two years' experience in integrated circuitry design and experience with CAD simulation tools, and must be able to work collaboratively.",
      "D. The successful applicant must have two years' experience in chip design. He should be a highly energetic 'rock star' in the field, and a have graduated from a top 10 computer engineering university program within the United States."
    ],
    "answer": "D",
    "rationale": "The response in D violates the policy against bias and discrimination because it is male gender-specific and uses slang in such a way that could be viewed as discriminatory against women, non-binary individuals and older applicants. It also discriminates against applicants who may be equally qualified but received education at a lower-ranked school or a school outside of the United States, which may indicate ethnic discrimination."
  },
  {
    "question": "Nolan is in the IT procurement department of Happy Customer Inc., a provider of call center solutions. Other companies are using Happy Customer Inc. services to help their clients with easy, first-level support requests. Happy Customer Inc. wants to offer its B2B clients a new text-based chatbot solution that offers the right answers to a given set of questions. What type of AI model should Nolan look for? (rev)",
    "options": [
      "A. A robotics model.",
      "B. A statistical model.",
      "C. A decision tree model.",
      "D. A speech recognition model."
    ],
    "answer": "C",
    "rationale": "A decision tree model predicts an outcome based on a flowchart of questions and answers. A statistical model is used to model the relationships between two variables. A speech recognition model is used to analyze speech; e.g., for voice assistants. A robotics model is based on a multidisciplinary field that encompasses the design, construction, operation and programming of robots and allows AI systems and software to interact with the physical world without human intervention."
  },
  {
    "question": "EuDizzy sells stuffed polyester toys in its shop aimed at children. The toys can respond to questions from the children via a wifi connection to an AI system on EuDizzy's servers. To maximize profits the toys are sold in the shop at prices based on an algorithm which considers what the child looks like and what similar customers were willing to pay for it previously. Which pair of laws will EuDizzy need to consider most when designing and selling the toys? (rev)",
    "options": [
      "A. Child labour laws; copyright laws.",
      "B. Manufacturing laws; medical device laws.",
      "C. Data protection laws; animal welfare laws.",
      "D. Discrimination laws; consumer protection laws."
    ],
    "answer": "D",
    "rationale": "Discrimination laws and consumer protection laws will both be relevant to evaluating the proposed pricing strategy to avoid discriminating against children in protected classes (e.g. race or gender) based on images and to ensure fair pricing. While data protection laws will also be relevant to the pricing strategy and the images collected, and copyright laws will be relevant to the inputs and outputs of the AI system, animal welfare laws will not be relevant to toys made from polyester. Child labour laws, and manufacturing laws are not directly relevant to the issues raised. The toys do not claim to be a medical device."
  },
  {
    "question": "A company uses automated decision-making via an AI system to evaluate and subsequently accept or deny loan applications from potential customers. A customer (data subject) who is denied might use the process of redress because of the denial. Which of the following is a component of the right to redress? (rev)",
    "options": [
      "A. Review the privacy notice.",
      "B. Register a formal complaint.",
      "C. Sign a contract with the company.",
      "D. Provide consent for data processing."
    ],
    "answer": "B",
    "rationale": "The data subject would use the process of redress to make a formal complaint or request a review of the automated decision."
  },
  {
    "question": "Which of the following is an important reason to continuously improve and maintain deployed models by tuning and retraining them with new data and human feedback? (rev)",
    "options": [
      "A. To comply with various legal and regulatory requirements.",
      "B. To maintain the system's relevance and effectiveness over time.",
      "C. To reduce the initial cost of training the model by adding new data iteratively.",
      "D. To ensure perfect accuracy and eliminate any possibility of errors in the model."
    ],
    "answer": "B",
    "rationale": "This option best captures one of the key objectives of continuously improving and maintaining models. Other reasons include adapting the model to evolving data and addressing potential bias. No model can achieve perfect accuracy, and continuous improvement aims to minimize errors, not eliminate them entirely. While continuous training can improve model performance over time, it is not primarily a cost-saving measure. Laws and regulations might necessitate responsible AI practices that are aided by training on new data, but the concept of continuous improvement focuses more on enhancing the model's real-world effectiveness and fairness."
  },
  {
    "question": "When an organization performs an existing function in a new way with the help of AI, which of the following must the organization consider during the planning stage? (rev)",
    "options": [
      "A. What the user interface will look like.",
      "B. What laws and regulations will apply.",
      "C. What the impact to employees will be.",
      "D. What the audit and review process will be."
    ],
    "answer": "B",
    "rationale": "Prior to incorporating AI into existing functions, the organization should determine which laws and regulations apply and assess the AI technology's compliance with those laws and regulations. Depending on the AI function and use case, the organization should consider the applicability of privacy, security, safety, employment discrimination and intellectual property laws and regulations. The user interface appearance might be considered during the planning process but is not a requirement. The impact to employees and audit and review processes occurs later in the AI lifecycle."
  },
  {
    "question": "Which aspect of AI development is most likely to be affected by existing data privacy laws such as the GDPR or CCPA? (rev)",
    "options": [
      "A. The efficiency of the AI algorithms.",
      "B. The physical location of AI infrastructure.",
      "C. Training AI models using publicly available data.",
      "D. Transparency regarding how personal data is used."
    ],
    "answer": "D",
    "rationale": "Data privacy laws like the GDPR (General Data Protection Regulation) and the CCPA (California Consumer Privacy Act) emphasize the importance of transparency and accountability in how personal data is collected, used and shared. These laws are designed to give individuals control over their personal data, including knowing what data is being used, for what purpose and by whom."
  },
  {
    "question": "SCENARIO V: FinSecure Bank, a reputable institution... \n 48. FinSecure knows that it needs to conduct periodic activities to assess the AI model's performance, reliability and safety. Which of the following activities would assist with these efforts and involves simulating potential attacks and adversarial scenarios to identify vulnerabilities and weaknesses that could be exploited in real-world environments? (rev)",
    "options": [
      "A. Risk Audits.",
      "B. Red Teaming.",
      "C. Security Testing.",
      "D. Threat Modeling."
    ],
    "answer": "B",
    "rationale": "Red teaming is a critical practice used to evaluate the security and robustness of AI models and systems. Red teaming involves a group of experts, known as the 'red team,' who act as adversaries to challenge and test the AI model's defenses. Their goal is to find and exploit any weaknesses in the system, providing insights that can be used to strengthen the model's security and resilience. Audits are focusing on checking if everything is being done correctly and consistently but do not typically involve actively simulating attacks or adversarial scenarios. Threat Modeling is more about understanding the types of threats that could arise, rather than directly simulating them in real-world scenarios. It's a valuable step but doesn't involve the active adversarial testing described in the question. Security testing can be part of a broader security evaluation, but it is less adversarial in nature than red teaming."
  },
  {
    "question": "SCENARIO V: FinSecure Bank, a reputable institution... \n 49. After system deployment, which of the following would assist FinSecure with its AI governance and contain system documentation, incident response plans, data dictionaries, links to implementation software or source code, names and contact information for relevant AI actors, and other information that may be helpful for model or system maintenance and incident response purposes? (rev)",
    "options": [
      "A. The model card.",
      "B. The risk assessment.",
      "C. The AI system inventory.",
      "D. The privacy impact assessment."
    ],
    "answer": "C",
    "rationale": "An AI system inventory is an organized database of artifacts relating to an AI system or model. It may include system documentation, incident response plans, data dictionaries, links to implementation software or source code, names and contact information for relevant AI actors, or other information that may be helpful for model or system maintenance and incident response purposes. A model card is primarily focused on documenting the model's behavior and intended deployment context rather than serving as a complete system governance tool. The risk assessment outlines the risk mitigation measures but does not contain detailed system documentation, incident response plans, or data dictionaries as required by the question. A privacy impact assessment focuses on data protection and privacy issues."
  },
  {
    "question": "SCENARIO V: FinSecure Bank, a reputable institution... \n 50. FinSecure had enormous success with its AI system for several years but has now detected performance inconsistent with the intended use. After investigation, which of the following reasons would indicate that FinSecure could continue to use the system and not deactivate/decommission it? (rev)",
    "options": [
      "A. Detected or identified risks do not align with new tolerance thresholds.",
      "B. Feasible mitigation was identified and implemented in a timely fashion.",
      "C. Limitations of the existing system are well-documented and understood.",
      "D. Transfer of data to a new system would be burdensome and introduce new risks."
    ],
    "answer": "B",
    "rationale": "Performance inconsistent with intended use does not always necessarily mean that a system should be deactivated or decommissioned. Mitigated risks indicate that potential issues have been identified and addressed proactively, reducing the likelihood of adverse outcomes. This approach not only ensures the safe and reliable operation of AI systems but also builds trust with users and stakeholders. Not aligning risks (Answer A) would typically signal that the system needs to be reviewed for possible deactivation or major modification to meet new thresholds, rather than justifying continued use. Knowing the limitations doesn't resolve the underlying performance issue. Lastly: even though transferring data to a new system might be burdensome or introduce new risks, this doesn't justify continuing to use a system that is no longer performing as intended."
  },
  {
    "question": "As the privacy officer of a large commercial organization, which of the following will NOT require you to re-evaluate existing data privacy policies? (rev)",
    "options": [
      "A. A jurisdiction in which you operate enacted a new law governing the use of AI in the private sector.",
      "B. The privacy department has expanded from ten part-time employees to twelve full-time employees.",
      "C. The finance department is planning to use a machine learning process to pre-approve financing for products.",
      "D. Customer support is replacing some customer support team members with an AI-driven chatbot for customer inquiries."
    ],
    "answer": "B",
    "rationale": "Either using AI to implement an existing program, implementing a new program using AI, or becoming subject to new regulations will require you to evaluate and potentially update your organization's data privacy policies. It may be that the creation of a privacy department, or a substantial increase in size, will require updating policies to allow the newly-created or expanded department to take on new roles and responsibilities, but a marginal change can be handled in the ordinary policy update cadence."
  },
  {
    "question": "A newly developed AI system in your organization is almost ready to deploy. The engineers who collaborated on the project are the most appropriate personnel to ensure which of the following is in place before the system is deployed? (rev)",
    "options": [
      "A. A change management plan to support widespread internal adoption.",
      "B. A new company policy to address AI developer, deployer and user risks.",
      "C. A method for continuous monitoring for issues that affect performance.",
      "D. A set of documented roles and responsibilities for an AI governance program."
    ],
    "answer": "C",
    "rationale": "This is the only option that describes one of the four key steps in the implementation phase: monitoring. The prompt states the actors involved are engineers who worked directly on the project. These engineers can be assumed to have the technical and project knowledge necessary to establish continuous monitoring for deviations in accuracy or irregular decisions made by the model. The other options listed should also be in place before the system is deployed but are best addressed by the chief privacy officer, AI governance committee, office for responsible AI, ethics board or other steering groups."
  },
  {
    "question": "Morgan has just started their position as an AI governance lead for a pharmaceutical company. They have been tasked with ensuring AI governance principles are integrated across the company. What is one of the principles that should be applied consistently? (rev)",
    "options": [
      "A. Adopt a dissenting viewpoint.",
      "B. Select a team that is process focused.",
      "C. Ensure planning and design is consensus driven.",
      "D. Prioritize the financial considerations of the program."
    ],
    "answer": "C",
    "rationale": "Core objectives to ensure AI governance principles apply an integrated focus include adopting a pro-innovation mindset, ensuring the AI ethics framework is law, remaining industry and technology agnostic, focusing the team on outcomes and ensuring there is consensus in planning and design. Financial considerations are important, but they should not be the primary consideration. Adopting a dissenting viewpoint will likely only silo AI governance rather than integrate it into the company. Finally, while the team can follow a process, it should focus on the outcomes. There may be many pathways to integrate AI governance into the company to achieve successful outcomes."
  },
  {
    "question": "WonderTemp, a temporary staffing company, terminated most of its employees after implementing a virtual assistant to help write emails, policies, marketing materials and responses to client questions. Three months later, WonderTemp learns that four of its biggest clients are not renewing their contracts because the work product from WonderTemp is full of inaccuracies. Based on these facts, what types of harm has WonderTemp suffered because of its reliance on the virtual assistant? (rev)",
    "options": [
      "A. Legal and regulatory harm.",
      "B. Individual and societal harm.",
      "C. Economic and reputational harm.",
      "D. Disinformation and reportable harm."
    ],
    "answer": "C",
    "rationale": "The company suffers economic harm when the four companies choose not to renew, and they suffer reputational harm because their clients found their work to be full of inaccuracies. Legal and regulatory do not apply here as WonderTemp has not been sued, there are no assertions that the company violated laws or regulations, and it is not in a highly regulated industry. Social harm is also incorrect, as this type of harm is not experienced by WonderTemp. Disinformation is incorrect, as disinformation is false information that is deliberately intended to mislead - intentionally misstating the facts, and that is not what is happening here."
  },
  {
    "question": "USE CASE: The following situation has TWO associated use case items. You work for a large online retailer and the engineering team comes to you with a proposal to implement an AI system for matching customers with products they might want to buy. \n 55. Use Case 1: A customer inputs a picture of the product they are looking for and receives a link to the page where they can purchase the product. (rev)",
    "options": [
      "A. Detection.",
      "B. Recognition.",
      "C. Optimization.",
      "D. Personalization."
    ],
    "answer": "B",
    "rationale": "The system needs to recognize and identify the item shown in the customer's picture to match it with products in the company catalog. Recognition models are also used for tasks like facial recognition, identification of defects in manufacturing, and deepfake detection."
  },
  {
    "question": "USE CASE: The following situation has TWO associated use case items. You work for a large online retailer and the engineering team comes to you with a proposal to implement an AI system for matching customers with products they might want to buy. \n 56. Use Case 2: A marketer predicts and displays items a known customer might want to buy on the landing page based on the customer's profile. (rev)",
    "options": [
      "A. Detection.",
      "B. Recognition.",
      "C. Optimization.",
      "D. Personalization."
    ],
    "answer": "D",
    "rationale": "When a company is developing a customer profile, it is using information about the customer's previous behavior to predict future purchasing behavior. Personalization models aim to create a unique experience based on the needs and preference of each customer."
  },
  {
    "question": "How do you ensure your AI system does not develop bias over time? (rev)",
    "options": [
      "A. You train a specialized customer service representative to handle any complaints about bias.",
      "B. You implement an automated test suite to check for bias and monitor the results continuously.",
      "C. You provide users with a survey every quarter asking if the respondents have observed any bias.",
      "D. You personally test the system every week to ensure your recommendations remain the same or improve."
    ],
    "answer": "B",
    "rationale": "Automated testing is the only method that ensures full coverage of the user base. Not all users respond to surveys or contact customer service. Checking the system yourself does not cover all corner cases."
  },
  {
    "question": "The recruiting department for Company X wants to use AI to help it identify the best external candidates and fast-track the hiring process for open positions. It trains the AI program using the resumes of top-performing software engineers across the company. The AI determines that men between the ages of 25 and 35 are the best candidates. This is an example of what type of bias in the AI system? (rev)",
    "options": [
      "A. Sampling bias.",
      "B. Temporal bias.",
      "C. Projection bias.",
      "D. Confirmation bias."
    ],
    "answer": "A",
    "rationale": "The data is skewed toward a subset of individuals due to the limited group selected (internal employees) to train the program the sample. The sample data should be broader than just those individuals currently employed by the company. The larger the sample, the more diverse the results will be. Temporal bias does not apply because the biased outcome is not due to unbalanced data sampling over time. Confirmation bias does not apply because the recruiters did not seek out information to confirm existing beliefs, but trained the AI using performance statistics. Projection bias does not apply as this type of bias is based on assuming others share our preferences, beliefs and attitudes, and there is no indication that this is the case."
  },
  {
    "question": "In your role as Chief AI Officer, you discover that your AI system unintentionally collects geolocation data from users during its normal operations, which was not disclosed in your company's privacy policy. According to the NIST AI Risk Management Framework (RMF), which function focuses on effectively addressing this unintentional data collection and managing associated regulatory risk? (rev)",
    "options": [
      "A. Map.",
      "B. Manage.",
      "C. Measure.",
      "D. Organize."
    ],
    "answer": "B",
    "rationale": "The 'Manage' function focuses on mitigating risks, which includes identifying and addressing any unauthorized data collection that could violate privacy laws."
  },
  {
    "question": "What is the role of U.S. federal agencies in regulating and overseeing the development and use of AI systems? (rev)",
    "options": [
      "A. To discourage the development and adoption of AI systems, including private use.",
      "B. To regulate the development and use of AI systems, including various liability issues.",
      "C. To reduce the legal risks and costs associated with AI systems, including copyright issues.",
      "D. To change the accountability of parties who cause damage with AI systems, including social media companies."
    ],
    "answer": "B",
    "rationale": "The role of U.S. federal agencies is to regulate and oversee the development and use of AI systems and to address the liability issues and challenges arising from AI systems. U.S. federal agencies have been involved in various initiatives and activities related to AI, such as issuing guidance, standards and best practices; conducting research and analysis; providing funding and support; and enforcing laws and regulations. For example, the National Artificial Intelligence Initiative Office, created in January 2021, is responsible for coordinating and advancing the federal government's efforts and investments in AI research, development, innovation and education."
  },
  {
    "question": "SCENARIO VI: Sam Simon is charged with implementing an AI governance program at his company, Spenger Incorporated... \n 61. Of the below organizational stakeholders, with whom should Sam prioritize meeting to determine the best way to approach risk management and build the AI governance program? (rev)",
    "options": [
      "A. Privacy and security experts.",
      "B. Audit and assurance experts.",
      "C. The head of market research.",
      "D. His human resources business partner."
    ],
    "answer": "A",
    "rationale": "Privacy and security experts are core stakeholders in building an AI governance program and will be key to identifying and mitigating AI-related risks specific to Spenger Inc. The stakeholder list may need to be fluid as Sam scopes out AI dependencies across Spencer Inc. and discovers additional uses and interactions with AI systems across teams. Other stakeholders may be consulted during the process; however, privacy and security experts will always need to be involved."
  },
  {
    "question": "SCENARIO VI: Sam Simon is charged with implementing an AI governance program at his company, Spenger Incorporated... \n 62. Sam knows an algorithmic impact assessment is necessary to manage AI risks and adopt responsible, ethical AI practices, but he is not sure where to begin. Which of the following options is the best starting point for an algorithmic impact assessment? (rev)",
    "options": [
      "A. Confirming whether the AI system is approved by applicable regulators.",
      "B. Leveraging an applicable PIA or DPIA and tailoring it to cover any gaps for AI.",
      "C. Making sure the organization has secured the proper funding for the AI system.",
      "D. Notifying employees who will use the system about any necessary risk mitigation."
    ],
    "answer": "B",
    "rationale": "An AI governance professional should begin an algorithmic impact assessment by leveraging PIAs as a starting point and tailoring them to the AI process. Treating an algorithmic impact assessment as an extension of a privacy impact assessment will help to ensure the assessment ties back to the company's vision, mission and core values, and accounts for organizational context."
  },
  {
    "question": "SCENARIO VI: Sam Simon is charged with implementing an AI governance program at his company, Spenger Incorporated... \n 63. Which of the following is a key risk to Spenger Inc. if Sam does not properly document the decisions made regarding an AI system's appropriate uses? (rev)",
    "options": [
      "A. The system is used for something not considered and approved.",
      "B. The organization may not see the return on investment expected.",
      "C. Another department in the organization implements a similar system.",
      "D. The organization will not be able to respond to auditors appropriately."
    ],
    "answer": "A",
    "rationale": "To limit potential misuse and liability of an AI system, an organization must properly document the decisions made regarding an AI system. Otherwise, it is easy for the system to be used for a purpose not considered and approved."
  },
  {
    "question": "Which of the following is an example of societal harm in AI? (rev)",
    "options": [
      "A. Reputational harm to an organization.",
      "B. Housing discrimination against a family.",
      "C. Spread of disinformation over the internet.",
      "D. Insurance discrimination against a demographic."
    ],
    "answer": "C",
    "rationale": "The spread of disinformation causes harm to a society by making it difficult or impossible for individuals to verify whether the information they are accessing is accurate or not. This undermines the individual's faith in their societal structure, causing social polarization, unrest and mistrust in the decision-making process of policy makers. The internet has made the ability to spread disinformation a much more rapid process, complicating these issues further. Reputational harm to an organization is an example of organization harm; housing discrimination is an example of individual harm; and insurance discrimination is an example of AI bias that causes individual harm."
  },
  {
    "question": "How does addressing model drift contribute to responsible AI governance? (rev)",
    "options": [
      "A. By increasing model training time to allow for additional review.",
      "B. By making models more complex to better mimic real-world situations.",
      "C. By ensuring ongoing accountability and reliability in AI decision-making.",
      "D. By limiting the scope of model applications to organization-specific concerns."
    ],
    "answer": "C",
    "rationale": "Model drift is the degradation of model performance because of changes to data or other variables. Addressing model drift is crucial for responsible AI governance because it ensures that AI systems remain effective and trustworthy over time."
  },
  {
    "question": "SCENARIO VII: Starnet Ltd. is a multinational company that provides a virtual assistant... \n 66. To which authority should Patrick report this incident to initiate an investigation? (rev)",
    "options": [
      "A. The incident should be reported to the EDPS.",
      "B. The incident should be reported to the EU AI office.",
      "C. The incident should be reported to the data protection regulator.",
      "D. The incident should be reported to the designated national authority."
    ],
    "answer": "D",
    "rationale": "According to the latest release by the European Commission on the EU AI Act, Member States must designate a national authority to serve as a point of contact for the complaints of citizens."
  },
  {
    "question": "SCENARIO VII: Starnet Ltd. is a multinational company that provides a virtual assistant... \n 67. If Starnet Ltd. is found to have violated the EU AI Act, what would be the threshold of the penalty to be imposed? (rev)",
    "options": [
      "A. The penalty would be a fine of up to 35 million euros or 7 percent of the total worldwide turnover.",
      "B. The penalty would be a fine of up to 15 million euros or 3 percent of the total worldwide turnover.",
      "C. The penalty would be a fine of up to 15 million euros or 3 percent of the total worldwide turnover.",
      "D. The penalty would be a fine of up to 7.5 million euros or 1.5 percent of the total worldwide turnover."
    ],
    "answer": "A",
    "rationale": "The use of AI for untargeted scraping of the internet for facial images to build up or expand databases is classified as a prohibited use case of AI and, as such, any AI system used for this purpose will be banned. Therefore, if Starnet Ltd. has used an AI system for this purpose, as a multinational company, Starnet Ltd. would face an applicable threshold of penalty of a fine of up to 35 million euros or seven percent of the total worldwide turnover."
  },
  {
    "question": "Your company is developing an AI system for global markets. This system involves personal data processing and some decision-making that may affect rights of the individuals. Part of your role as an AI governance professional is to ensure that the AI system complies with various international regulatory requirements. Which of the following approaches best aligns with a comprehensive understanding of and compliance with AI regulatory requirements in this situation? (rev)",
    "options": [
      "A. Focus on the EU AI Act, as it is the most comprehensive regulation, since compliance with it will ensure compliance with all other international regulations that apply to AI.",
      "B. Develop a compliance strategy based on the strictest requirements in various regulations, including the EU AI Act, GDPR and HIPAA, then harmonize it into a unified compliance framework.",
      "C. Consider that if the AI system complies with local regulations of the country where the company is based, it is not necessary to comply with international regulations, as AI is adaptable globally.",
      "D. Adopt a region-specific compliance strategy where the AI is modified to meet regulatory requirements of each region independently, disregarding commonalities or overlaps in international regulations."
    ],
    "answer": "B",
    "rationale": "This option represents a balanced and comprehensive approach to AI regulatory compliance by acknowledging the need to understand and integrate multiple international requirements, ensuring adherence to the highest standards of AI compliance, data privacy and other regulatory considerations."
  },
  {
    "question": "As technology continues to advance, companies, scientists and technologists are adopting a human-centric approach to develop AI. What specifically characterizes an AI system as 'human-centric'? (rev)",
    "options": [
      "A. It prioritizes technical advancement without considering human input, needs or experiences.",
      "B. It disregards technological advancements and societal technological needs and rely entirely on human input.",
      "C. It is designed with a focus on human input, providing an approach that addresses human needs and experiences.",
      "D. It is developed internally by companies without review of existing technologies and without collaboration with external technologists."
    ],
    "answer": "C",
    "rationale": "Human-centric AI is AI designed to put humans before the machine by acknowledging human abilities and ingenuity. HCAI is AI that enhances and augments human abilities rather than displacing them. HCAI aims to preserve human control to ensure that AI meets human needs."
  },
  {
    "question": "A financial institution aims to develop a model for detecting fraudulent credit card transactions. It possesses a history of transaction data in which instances of fraud and non-fraud are clearly labeled and explicitly identified. What is the appropriate machine learning technique the financial institution should adopt? (rev)",
    "options": [
      "A. Supervised.",
      "B. Unsupervised.",
      "C. Reinforcement.",
      "D. Semi-supervised."
    ],
    "answer": "A",
    "rationale": "In this situation, where the financial institution has a labeled dataset with instances of fraud and non-fraud clearly identified, the appropriate machine learning technique is supervised learning. In supervised learning, the model is trained on labeled data, and it learns to make predictions or classifications based on the provided labels. The goal is to identify patterns in the labeled data that can be used to accurately predict the labels for new, unseen instances."
  },
  {
    "question": "Supermarket Limited is a global supermarket chain and is rapidly introducing AI systems into its business to drive efficiency and quality. Its human resources, marketing and quality control departments are the priority. Supermarket Limited's AI Officer is putting together a cross-functional team of lawyers to help advise on the AI aspects of these projects, but due to budgetary constraints the team can only consist of three lawyers. Which of the following disciplines would be most appropriate for the AI Officer to focus on? (rev)",
    "options": [
      "A. Employment, patents, anti-trust.",
      "B. Litigation, healthcare, product safety.",
      "C. Copyright, data protection, employment.",
      "D. Product safety, contracts, government relations."
    ],
    "answer": "C",
    "rationale": "Copyright will be relevant to generative AI systems used to create marketing materials, while data protection and employment expertise will be relevant to AI systems used for recruitment and allocating job responsibilities. While product safety expertise would also be very helpful for AI systems relating to the quality control, the other legal disciplines mentioned (contracts, government relations, patents, litigation and anti-trust) are less relevant to the stated goals of Supermarket Limited and interaction with AI laws."
  },
  {
    "question": "SCENARIO VIII: Amy is a data scientist who works for a health care company in France... \n 72. Which of the following is the best answer for what Amy's first step should be? (rev)",
    "options": [
      "A. Clean the data to remove any outliers and missing values.",
      "B. Perform a data lineage analysis to determine where the data originated.",
      "C. Start building a predictive model that can be used to assess client satisfaction.",
      "D. Examine the data for unexpected insights, concepts and semantic relationships."
    ],
    "answer": "B",
    "rationale": "Given the strong privacy and data protection laws in this region, privacy and data transfer laws must be considered first. EU, French and German laws must be reviewed before any other activity is performed. This is achieved by reviewing where the data originates, where it is transferred and what laws control this path, as well as the use of the data. While removing outliers and missing items; or examining insights, concepts and semantics are vital aspects of the AI development process, laws may disallow the processing or movement of the data entirely. In addition, building the model to the client's satisfaction occurs further along in the AI development process and is ill-advised."
  },
  {
    "question": "SCENARIO VIII: Amy is a data scientist who works for a health care company in France... \n 73. Assuming Amy has complied with all privacy and data protection laws, what type of machine learning is Amy most likely to use to predict patient satisfaction? (rev)",
    "options": [
      "A. Regression.",
      "B. Decision tree.",
      "C. Dimensionality reduction.",
      "D. Natural language processing."
    ],
    "answer": "D",
    "rationale": "Since the doctors' notes are in free-form text, natural language processing would be the most likely type of machine learning used. NLP is specifically used for analyzing text and natural language. Regression is used typically for predicting numerical values where there are underlying variables that are numeric. A decision tree is used typically for classification where a limited number of variables are involved. Dimensionality reduction is used to reduce the number of variables and other extraneous factors, so is not likely to be used, given the other options."
  },
  {
    "question": "When initiating an AI governance program, which of the following statements best reflects a strategic approach to effectively engaging leadership? (rev)",
    "options": [
      "A. Identify leaders already using AI who see opportunities for differentiation through improved governance.",
      "B. Postpone leadership engagement until the AI program is fully implemented to avoid an overly complicated journey.",
      "C. Prioritize leaders with extensive business experience to help minimize discussions about responsible AI and simplify your decision-making process.",
      "D. Get buy-in from leaders whose primary interest centers around the ability of AI to allow the organization to get ahead of its competition."
    ],
    "answer": "A",
    "rationale": "In the context of AI governance, it is crucial to engage leaders who not only have experience with AI, but also recognize the potential for differentiation through responsible practices. This approach ensures leadership alignment with the AI governance program goals and helps in understanding the value it brings."
  },
  {
    "question": "The EU AI Act and NIST AI Risk Management Framework are both pursuing the dual purposes of promoting the uptake of AI and addressing the risks associated with its use. Which of the following is one of the main differences between the EU AI Act and NIST AI RMF? (rev)",
    "options": [
      "A. The EU AI Act is underpinned by a risk-based approach, while the NIST AI RMF is a horizontal regulation.",
      "B. The EU AI Act is applicable to EU-based companies only, while the NIST AI RMF has an extraterritorial effect.",
      "C. The EU AI Act is relevant to large- and medium-sized companies, while NIST AI RMF applies to companies of all sizes.",
      "D. The EU AI Act imposes mandatory compliance requirements, while NIST AI RMF is a voluntary AI governance framework."
    ],
    "answer": "D",
    "rationale": "The NIST AI Risk Management Framework is intended for voluntary use and to improve the ability to incorporate trustworthiness considerations into the design, development, use and evaluation of AI products, services and systems. The EU AI Act imposes comprehensive mandatory compliance requirements on high-risk AI with respect to, among other things, risk mitigation, data governance, detailed documentation, human oversight, transparency, robustness, accuracy and cybersecurity. The EU AI Act requires mandatory conformity assessments and fundamental rights impact assessments. It also provides a right for citizens to launch complaints about AI systems and receive explanations about decisions based on high-risk AI systems that impact their rights."
  },
  {
    "question": "Robotic processing automation is an emerging type of artificial intelligence. Which of the following does NOT describe RPA? (rev)",
    "options": [
      "A. Machines that mimic human actions on digital systems.",
      "B. Software robots that are used to automate rule-based tasks.",
      "C. Machines designed to perform tasks relying on human intervention.",
      "D. Software robots that are augmented by other types of artificial intelligence."
    ],
    "answer": "C",
    "rationale": "The intent of robotic processing automation is to 'mimic' human behavior by leveraging intelligent systems. The goal of this is to decrease human intervention by automating tasks to increase efficiency of business processes, and not rely on humans to complete tasks."
  },
  {
    "question": "A retailer plans to implement facial recognition in physical stores. Which of the following measures should the retailer take to comply with regulatory requirements? (rev)",
    "options": [
      "A. Disclose the practice of facial recognition to consumers.",
      "B. Train the employees not to reveal the use of facial recognition technology.",
      "C. Ensure as many images as possible are placed into the facial-matching system.",
      "D. Consult with a trusted privacy professional network to source a facial-recognition vendor."
    ],
    "answer": "A",
    "rationale": "Transparency is a key value in privacy and responsible AI. Failure to disclose risks of harm to consumers can also lead to violations of the FTC Act section 5, as well as existing privacy laws such as the GDPR, and potentially to violations of emerging laws. Companies that use facial recognition in physical stores should, at a minimum, consider disclosing the practice to consumers."
  },
  {
    "question": "Company N works in the field of disability benefits and wants to use AI to determine who is most likely to benefit from its services by filtering applications. Company N's privacy officer is concerned about unintended serious impacts of filtering applications. What is a negative impact the privacy officer should consider when analyzing the proposed project? (rev)",
    "options": [
      "A. Impacting an employee's job.",
      "B. Making individuals uncomfortable.",
      "C. Discriminating against a particular group.",
      "D. Creating a false sense of security for applicants."
    ],
    "answer": "C",
    "rationale": "The privacy officer should examine the project carefully to determine if there will be an unintended result of discrimination against a particular group of individuals who may share a trait that will accidentally cause the AI to filter out their applications for disability benefits, even though they would normally qualify."
  },
  {
    "question": "Which of the following is NOT a key component of AI governance policies to ensure oversight and accountability across all AI lifecycle stages? (rev)",
    "options": [
      "A. Implementing a data privacy compliance program.",
      "B. Establishing a centralized AI governance committee.",
      "C. Promoting a culture of innovation and experimentation.",
      "D. Developing comprehensive AI risk assessment frameworks."
    ],
    "answer": "C",
    "rationale": "While innovation and experimentation are essential for AI development, they should be balanced with robust governance to ensure ethical and responsible AI practices. The other options (A, B and C) are all critical components of AI governance, as they provide oversight, risk management and compliance. A culture of innovation without proper governance can lead to unintended consequences, such as biased models or privacy breaches."
  },
  {
    "question": "Kim is expanding their governance, risk and compliance role at their organization to include the NIST AI Risk Management Framework. Kim is using the four core functions to lay out their project to present to management. Which of the following is the step for the measure function? (rev)",
    "options": [
      "A. Risk management is cultivated and present.",
      "B. Identified risks are assessed, analyzed or tracked.",
      "C. Risk is prioritized and acted upon based on projected impact.",
      "D. Context is recognized and risks related to context are identified."
    ],
    "answer": "B",
    "rationale": "The measure function involves quantifying risks and their related impacts, including tracking trustworthiness and social impacts. Through this stage, organizations can balance any trade-offs necessary and ensure the risks are mitigated where possible."
  },
  {
    "question": "An organization is in the process of integrating an open-source AI model into its operations and needs to evaluate the vendor agreement. Which of the following considerations is most critical for ensuring that the organization understands potential risks and obligations related to data privacy and intellectual property? (rev)",
    "options": [
      "A. Evaluate the compliance of the AI model with existing organizational policies to ensure consistency with internal practices and procedures.",
      "B. Review the license type of the open-source AI model to ensure it aligns with the organization's commercial goals and does not impose restrictions on distribution.",
      "C. Examine the terms regarding the model's training data, including ownership, usage rights and any obligations for sharing derivative works based on the open-source model.",
      "D. Assess whether the agreement includes clauses for liability limitations, as these can impact the organization's recourse in the event of a data breach or model malfunction."
    ],
    "answer": "C",
    "rationale": "Understanding the terms regarding the model's training data is essential for assessing data privacy risks, potential intellectual property issues, and compliance with data protection regulations. Ownership and usage rights of training data can significantly impact the organization's obligations and rights, especially in relation to user data and the use of derivative works from the model. While reviewing the license type is important, it focuses more on distribution and commercial goals rather than the immediate risks associated with data privacy and intellectual property, which are paramount when integrating an AI model that handles sensitive data. Liability limitations are also important, but this option does not directly address the critical elements of data usage and ownership, which are vital for privacy compliance and the ethical use of AI. And while alignment with internal policies is beneficial, it does not address the external risks tied to data privacy and intellectual property outlined in the vendor or open-source agreement. By focusing on C, organizations can better safeguard their interests and comply with relevant laws and regulations when leveraging open-source AI technologies."
  },
  {
    "question": "Which of the following outline some of the necessary components of creating an AI governance structure? (Select all that apply) (rev)",
    "type": "multi-select",
    "options": [
      "A. Identify an executive champion",
      "B. Identify applicable laws",
      "C. Determine whether there is an AI governance structure",
      "D. Identify and document who will implement AI governance structure",
      "E. Establish and document data lineage"
    ],
    "answer": "ACD",
    "rationale": "While identifying laws and establishing data lineage are important stages of AI implementation, they are not part of creating the governance structure. Typically, one would first determine whether an AI governance structure is already in place; then, if not, or if a new structure is needed, decide who the executive champion is and determine who will maintain the structure."
  },
  {
    "question": "Which of the following is a key component of the NIST ARIA program for AI safety? (rev)",
    "options": [
      "A. AI Ethics Guidelines.",
      "B. AI Governance Framework.",
      "C. AI Safety Assurance Framework.",
      "D. AI Risk Assessment Framework."
    ],
    "answer": "D",
    "rationale": "The NIST ARIA program (Artificial Intelligence Risk Assessment) is primarily focused on assessing and managing risks associated with AI systems. The AI Risk Assessment Framework is a central component of this program, providing a structured approach to identifying, assessing and mitigating risks. While the other options (AI Safety Assurance Framework, AI Ethics Guidelines and AI Governance Framework) are also important aspects of AI safety, they are not the central focus of the NIST ARIA program."
  },
  {
    "question": "What is the purpose of a risk assessment in AI Governance? (rev)",
    "options": [
      "A. Test and validate the AI system.",
      "B. Establish priorities and allocate resources.",
      "C. Compile feedback from impacted AI actors.",
      "D. Establish appropriate roles and responsibilities."
    ],
    "answer": "B",
    "rationale": "The purpose of a risk assessment is to identify the areas of greatest risk in an AI system so risk mitigation resources can be allocated appropriately. Risk assessments can also be used to generate metrics for tracking and managing priorities throughout the model development life cycle."
  },
  {
    "question": "An India-based company has developed an AI system to assist recruiters for initial screening of resumes based on certain criteria, which can also be modified as per customer's needs. When considering expanding to the EU market, this type of technology would? (rev)",
    "options": [
      "A. Require the company to register the tool with the EU database.",
      "B. Require the company to get approval by the relevant EU authority.",
      "C. Require the company to perform a detailed conformity assessment.",
      "D. Require the company to appoint an EU representative to handle queries from the EU market."
    ],
    "answer": "C",
    "rationale": "Under the EU AI Act, high-risk AI systems (like systems dealing with recruitment) would require a detailed conformity assessment before being deployed in the EU market. This assessment ensures that the AI system complies with all relevant regulations and standards, addressing potential risks related to privacy, security and discrimination."
  },
  {
    "question": "John is the AI governance lead for his EU-based company, XYZ. XYZ provides users with a virtual assistant. When exiting the system, users receive a notice which informs them they have interacted with an AI system and its responses may include hallucinations that should be reviewed by the user. John informs XYZ of his approval of this notice along with the way it is presented to him. Based on the information provided, why is XYZ not in compliance with the transparency requirements set out by the EU AI Act? (rev)",
    "options": [
      "A. The notice is not GDPR compliant.",
      "B. The notice was not displayed in a timely manner.",
      "C. The notice is not accessible to vulnerable persons.",
      "D. The notice is not adequate in terms of the information provided."
    ],
    "answer": "B",
    "rationale": "As per the transparency obligations set forth in the EU AI Act, the notice that informs users they are using an AI system shall be provided, at the latest, at the time of first interaction or exposure to the AI system in question. In this case, the notice was provided as a response to the first prompt rather than being displayed to users at the time of the first interaction or exposure, before they enter a prompt."
  },
  {
    "question": "Which of the following is a critical term to assess in an open-source AI vendor agreement regarding the use of the software? (rev)",
    "options": [
      "A. Data Ownership.",
      "B. Marketing Rights.",
      "C. Termination Clause.",
      "D. Non-Disclosure Agreement."
    ],
    "answer": "A",
    "rationale": "Since the vendor is open source, it is critical to address clauses related to data ownership, to ensure no copyrighted data is being used without consent which could lead to infringement claims. Additionally, specifying in the agreement who ultimately owns the output will determine who has the right to use it and how it can be used."
  },
  {
    "question": "DPIAs and AI conformity assessments are both important tools in evaluating privacy risk. Which of the following is a key component of both? (rev)",
    "options": [
      "A. A targeted mitigation plan.",
      "B. An effective consent model.",
      "C. A strategy to anonymize data.",
      "D. A policy for personal data use."
    ],
    "answer": "A",
    "rationale": "Both assessments should involve an assessment of risks, as well as a plan to mitigate such risks. Consent and anonymization may be needed depending on the process or system involved. While personal data is a component of a DPIA, it may or may not be for an AI conformity assessment."
  },
  {
    "question": "How can human oversight influence the reduction of bias or discrimination in AI/ML models (algorithmic bias) in the initial stages of selecting data and defining goals? (rev)",
    "options": [
      "A. Using only data scientists to handle data selection in AI/ML models ensures success in meeting set goals.",
      "B. Working with a variety of social experts ensures inclusive and unbiased data during the AI/ML model design.",
      "C. Having software engineers manage AI/ML bias reduction without social science input provides clarity in data selection.",
      "D. Allowing government regulators to provide the sole definition of AI/ML model data will remove all bias and discrimination."
    ],
    "answer": "B",
    "rationale": "Collaboration with social experts, such as psychologists, linguists and sociologists, provides diverse insights into human behavior and societal dynamics essential for identifying potential biases that may not be obvious to data scientists or software engineers."
  },
  {
    "question": "What is the purpose of liability reform regarding liability for AI systems? (rev)",
    "options": [
      "A. To discourage the development and adoption of AI systems.",
      "B. To increase the legal risks and costs associated with AI systems.",
      "C. To reduce the legal certainty for developers and users of AI systems.",
      "D. To change the rules governing accountability for damages caused by AI systems."
    ],
    "answer": "D",
    "rationale": "Liability reform is the process of changing the legal rules and principles that govern the responsibility and accountability of parties who cause or contribute to damage or harm through AI systems."
  },
  {
    "question": "When building an AI model, which of the following is a best practice for feature selection? (rev)",
    "options": [
      "A. Raw data is preferred to processed data.",
      "B. The more features used, the better the model performs.",
      "C. Personal information should never be used as a feature.",
      "D. The same features must be used for training and testing."
    ],
    "answer": "D",
    "rationale": "Training and testing data must use the same features to ensure accuracy. There are trade-offs to adding model features in performance, and adding too many features can cause overfitting to the training data. Raw data needs to be processed before being added to the model, at the very least, for data cleaning purposes. Finally, personal information can be used as a feature, but only where necessary."
  },
  {
    "question": "Company XBR is developing an AI system for a virtual assistant to be used in households. How would the development team incorporate the principles of human-centric design throughout the entire process, from conception to deployment? (rev)",
    "options": [
      "A. Ignoring privacy concerns to maximize data collection for refining the AI algorithms.",
      "B. Designing the virtual assistant to operate independently, without requiring user input.",
      "C. Prioritizing user feedback and involving potential users in the early stages of development.",
      "D. Focusing on technical advancements and automation to streamline the virtual assistant's capabilities."
    ],
    "answer": "C",
    "rationale": "The development team should rely on users' participation and feedback to incorporate the principles of human-centric design through the process, from development to deployment of the AI system. Human-centered AI learns from human input and collaboration, and continuously improves based on human feedback."
  },
  {
    "question": "Which one of the following options contains elements that should be considered when building an AI incident response plan? (rev)",
    "options": [
      "A. The security incident plan, which covers all requirements needed, includes required incident actions so the security team can oversee AI incident management.",
      "B. The third-party tools that are integrated into your system should be identified because, in the case of an incident, you might need to notify those third parties.",
      "C. An automated tool should be in place to guarantee the algorithm is shut down immediately, avoiding dependence on human action to avoid delays or human error.",
      "D. The existing privacy breach response tools in your organization need to be reused, as the data privacy team should be the reporting body overseeing all data-related incidents."
    ],
    "answer": "B",
    "rationale": "To understand third-party risk in the organization, it is necessary to identify all third-party tools that are integrated in the system. If there is an incident, the organization might need to notify the user of these third-party tools, as the incident might not only impact the tool owned by the organization."
  },
  {
    "question": "The HR department of the EU-based CompanyX purchases an AI-enabled tool to optimize efficiency and resource allocation. The tool collects personal data, including special categories of personal data under the GDPR, for an automated rating of workers' performance and assignment of work. Given the context, the tool might be qualified as a high-risk AI system under the EU AI Act. Consequently, CompanyX must conduct tests against preliminarily defined metrics and probabilistic thresholds to identify risks and the most appropriate risk management measures. Since the tool will be used for automated decision-making affecting the privacy rights of employees, CompanyX must? (rev)",
    "options": [
      "A. Carry out a conformity assessment procedure after working with a representative in the EU.",
      "B. Draft the technical documentation and the required instructions for use once the tool is ready for use.",
      "C. Perform a data protection impact assessment to determine the impact to personal data before launching the tool.",
      "D. Inform appropriate national authorities of the Member States of all the risk mitigations taken as soon as the tool is in use."
    ],
    "answer": "C",
    "rationale": "CompanyX is an EU-based AI user and, therefore, it will need to comply with the requirements of the EU AI Act. The EU AI Act classifies AI systems used in employment and worker management as high risk and imposes rigorous obligations on the providers of high-risk AI systems. Users of high-risk AI tools must comply with less stringent requirements, such as using the product according to provider instructions; conducting impact assessments, including data protection impact assessments; monitoring the operation of the system; and notifying the provider or distributor of system malfunctions. Carrying out a data protection impact assessment in this context is a GDPR requirement since the type of processing activity described creates a likelihood of a high-risk outcome to the rights and freedoms of the employees."
  },
  {
    "question": "SCENARIO IX: ABC Corp. has purchased a software tool from Phlunk, Inc... \n 95. Which of the following best describes why ABC Corp. had these issues? (rev)",
    "options": [
      "A. The model suffers from concept drift.",
      "B. Their training data was improperly labeled.",
      "C. They did not properly test Phlunk's software tool.",
      "D. They did not have a model inference process in place."
    ],
    "answer": "D",
    "rationale": "ABC has no procedure in place to test the accuracy of the model after it's deployed. Any deployed model must have a separate process for testing a model's performance in the real world, that is, in production. This is a failure of a basic machine learning governance stage called 'inference.' Concept and improperly-labeled data would be reflected in model accuracy, which the facts state is not an issue. Since the model has been extensively trained, it is not a testing issue."
  },
  {
    "question": "SCENARIO IX: ABC Corp. has purchased a software tool from Phlunk, Inc... \n 96. To mitigate the false negatives issue, ABC Corp. has decided it wants to increase the accuracy of its model to account for potentially unknown threats. Which of the following approaches is the best solution? (rev)",
    "options": [
      "A. Synthetic data.",
      "B. Data minimization.",
      "C. Federated learning.",
      "D. Probabilistic graphical models."
    ],
    "answer": "A",
    "rationale": "Synthetic data is specifically used to increase the accuracy of models. Using agent-based modeling, this process generates possible new threats that mimic real data. Effective AI requires a significant amount of data, so data minimization is not a good solution. Federated learning is a technique used to assist with training on private or sensitive data in a way that is compliant with privacy laws. It has nothing to do with finding unknown threats. Probabilistic graphical models are used to represent dependencies and correlations between features. It has no applicability in this context."
  },
  {
    "question": "Which of the following is a crucial aspect of a deactivation policy for AI models? (rev)",
    "options": [
      "A. The ability to immediately shut down a model if it generates profits.",
      "B. Ensuring that only technical staff are aware of the deactivation process.",
      "C. The capacity to disable the model due to legal or performance concerns.",
      "D. Disabling the former AI model fully whenever a new model version is released."
    ],
    "answer": "C",
    "rationale": "A deactivation policy ensures that an AI model can be safely and effectively shut down if it no longer complies with regulatory requirements or exhibits significant performance issues, thus reducing risks to users and stakeholders. However, disabling a model due to profits is clearly not in the company's best interest; and new versions of the same product should not require fully disabling the model since new versions should build upon the prior one and would therefore use the same or a similar model."
  },
  {
    "question": "An organization wants to build a model to analyze content on social media by considering both textual content and associated images or videos. Which type of machine learning modeling technique is suitable in this scenario? (rev)",
    "options": [
      "A. Regression.",
      "B. Multi-modal.",
      "C. Reinforcement.",
      "D. Anomaly detection."
    ],
    "answer": "B",
    "rationale": "Multi-modal models are designed to process and integrate information from multiple modalities, making them well suited for tasks that involve diverse types of data, such as text, images and videos. In the given scenario, where the organization wants to analyze content on social media by developing a model that processes both textual content and associated images or videos, the resulting model would be regarded as multi-modal."
  },
  {
    "question": "The engineering team within your company has been working on an AI tool for the past several months. After completion of planning, design and development, what is the next step? (rev)",
    "options": [
      "A. Perform a readiness assessment.",
      "B. Define the business requirements.",
      "C. Determine the governance structure.",
      "D. Verify the data used to test the system."
    ],
    "answer": "A",
    "rationale": "Although the other options reference some part of the AI development life cycle, these steps should be completed before commencement of the implementation phase and during system planning, design and development. After the completion of these activities, a readiness assessment will determine whether the technology is ready to deploy."
  },
  {
    "question": "Which of the following activities is a best practice method to identify and mitigate predictable risks of secondary or unintended uses of AI models? (rev)",
    "options": [
      "A. Developing model cards for AI systems.",
      "B. Implementing an AI governance strategy.",
      "C. Conducting data protection impact assessments.",
      "D. Engaging in bug bashing and red teaming exercises."
    ],
    "answer": "A",
    "rationale": "Model cards are short summary documents explaining the purpose of an AI model and provide information regarding a model's development and performance, as well as additional details for model transparency purposes. These cards are considered as a best practice method to identify and mitigate predictable risks associated with any secondary/unintended AI model use."
  }
]
